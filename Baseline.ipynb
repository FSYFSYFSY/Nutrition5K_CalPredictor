{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08eaaeca",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8fc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe764f1b",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e48cf",
   "metadata": {},
   "source": [
    "### Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2111b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 if_train = True,\n",
    "                 data_dir = \"train\",\n",
    "                 color_dir = \"color\",\n",
    "                 depth_dir = \"depth_raw\",\n",
    "                 rgb_name = \"rgb.png\",\n",
    "                 depth_name=\"depth_raw.png\",\n",
    "                 csv_name = \"nutrition5k_train.csv\",\n",
    "                 transform = False,\n",
    "                 ):\n",
    "        self.root = root\n",
    "        self.data = self.root / data_dir\n",
    "        self.color_dir  = self.data / color_dir\n",
    "        self.depth_dir = self.data / depth_dir\n",
    "        self.rgb_name = rgb_name\n",
    "        self.depth_name = depth_name\n",
    "        self.if_train = if_train\n",
    "        self.transform = transform\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "\n",
    "\n",
    "        if self.if_train:\n",
    "            df = pd.read_csv(self.root / csv_name)\n",
    "            self.id2cal = {str(r[\"ID\"]) : float(r[\"Value\"]) for _, r in df.iterrows()}\n",
    "\n",
    "        rgb_paths = sorted((p / rgb_name for p in self.color_dir.glob(\"dish_*\") if (p / rgb_name).exists()))\n",
    "        if not rgb_paths:\n",
    "            raise RuntimeError(f\"Found 0 images in {self.color_dir}.\")\n",
    "        \n",
    "        self.samples = []\n",
    "        if self.if_train:\n",
    "            for rgb_path in rgb_paths:\n",
    "                dish_id = rgb_path.parent.name\n",
    "                if dish_id not in self.id2cal:\n",
    "                    print(f\"Warning: {dish_id} not found in CSV.\")\n",
    "                depth_path = None\n",
    "                if self.depth_dir is not None:\n",
    "                    depth_path = self.depth_dir / dish_id / self.depth_name\n",
    "\n",
    "                self.samples.append((rgb_path, depth_path, self.id2cal[dish_id]))\n",
    "\n",
    "        else:\n",
    "            for rgb_path in rgb_paths:\n",
    "                dish_id = rgb_path.parent.name\n",
    "                depth_path = None\n",
    "                if self.depth_dir is not None:\n",
    "                    depth_path = self.depth_dir / dish_id / self.depth_name\n",
    "\n",
    "                self.samples.append((rgb_path, depth_path, None))\n",
    "                \n",
    "        #print(f\"Total samples: {len(self.samples)}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path, depth_path, cal = self.samples[idx]\n",
    "        rgb = Image.open(rgb_path).convert(\"RGB\")\n",
    "        depth = Image.open(depth_path).convert(\"L\")\n",
    "\n",
    "        rgb = self.to_tensor(rgb)\n",
    "        depth = self.to_tensor(depth)\n",
    "\n",
    "\n",
    "        if self.if_train == True:\n",
    "            cal = torch.tensor(cal, dtype=torch.float32)\n",
    "            return rgb, depth, cal\n",
    "        else:\n",
    "            return rgb, depth\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7bd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/lhg45/Desktop/COMP90086/PJ/Nutrition5K\n"
     ]
    }
   ],
   "source": [
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73698119",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(root=Path.cwd(), if_train=True, transform=False)\n",
    "test_set = MyDataset(root=Path.cwd(), data_dir=\"test\", if_train=False, transform=False)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "val_ratio = 0.1\n",
    "val_size = int(dataset_size * val_ratio)\n",
    "train_size = dataset_size - val_size\n",
    "train_subset, val_subset = random_split(train_set, [train_size, val_size])\n",
    "\n",
    "#torch.manual_seed(42) \n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=16, shuffle=False,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=16, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a959b7",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3080a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(c_in, c_out, k=5, s=1, p=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(c_in, c_out, kernel_size=k, stride=s, padding=p, bias=False),\n",
    "        nn.BatchNorm2d(c_out),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class RGBBranch(nn.Module):\n",
    "    def __init__(self, in_ch=3):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            conv_block(in_ch, 32),                \n",
    "            conv_block(32, 32),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(32, 64),\n",
    "            conv_block(64, 64),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(64, 128),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(128, 256),\n",
    "            nn.MaxPool2d(2),                     \n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.gap(x).flatten(1)               \n",
    "        return x\n",
    "\n",
    "class DepthBranch(nn.Module):\n",
    "    def __init__(self, in_ch=1):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            conv_block(in_ch, 16),\n",
    "            conv_block(16, 16),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(16, 32),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(32, 64),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(64, 128),\n",
    "            nn.MaxPool2d(2),                      \n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.gap(x).flatten(1)              \n",
    "        return x\n",
    "\n",
    "class RGBDNet(nn.Module):\n",
    "\n",
    "    def __init__(self, use_dropout=True):\n",
    "        super().__init__()\n",
    "        self.rgb = RGBBranch(3)\n",
    "        self.depth = DepthBranch(1)\n",
    "\n",
    "        fusion_dim = 256 + 128\n",
    "        mlp = [\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if use_dropout:\n",
    "            mlp.append(nn.Dropout(0.1))\n",
    "        mlp += [\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        ]\n",
    "        self.head = nn.Sequential(*mlp)\n",
    "\n",
    "    def forward(self, rgb, depth):\n",
    "        f_rgb = self.rgb(rgb)       \n",
    "        f_d   = self.depth(depth)    \n",
    "        f     = torch.cat([f_rgb, f_d], dim=1)\n",
    "        out   = self.head(f).squeeze(1)  \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b764af9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c14a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RGBDNet()  \n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_smapes, val_smapes = [], []\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, smape_sum, n_batches = 0.0, 0.0, 0\n",
    "    print(\"Start epoch: \" + str(epoch+1))\n",
    "    image_count = 0\n",
    "\n",
    "    for rgb, depth, cal in train_loader:\n",
    "        rgb, depth, cal = rgb.to(device), depth.to(device), cal.to(device)\n",
    "        pred = model(rgb, depth)\n",
    "        loss = criterion(pred, cal)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * rgb.size(0)\n",
    "        smape_batch = torch.mean( 2 * torch.abs(pred - cal) / (torch.abs(pred) + torch.abs(cal) + 1e-8)).item()\n",
    "        smape_sum += smape_batch\n",
    "        n_batches += 1\n",
    "\n",
    "        image_count += rgb.size(0)\n",
    "        print(f\"Processed {image_count} images\", end='\\r')\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_smape = smape_sum / n_batches\n",
    "    train_losses.append(train_loss)\n",
    "    train_smapes.append(train_smape)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, smape_sum, n_batches = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for rgb, depth, cal in val_loader:\n",
    "            rgb, depth, cal = rgb.to(device), depth.to(device), cal.to(device)\n",
    "            pred = model(rgb, depth)\n",
    "            loss = criterion(pred, cal)\n",
    "            val_loss += loss.item() * rgb.size(0)\n",
    "            smape_batch = torch.mean( 2 * torch.abs(pred - cal) / (torch.abs(pred) + torch.abs(cal) + 1e-8)).item()\n",
    "            smape_sum += smape_batch\n",
    "            n_batches += 1\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_smape = smape_sum / n_batches\n",
    "    val_losses.append(val_loss)\n",
    "    val_smapes.append(val_smape)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Train MAPE: {train_smape*100:.3f}%, Val MAPE: {val_smape*100:.3f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40963b3",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('MSE Loss Curve'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot([m*100 for m in train_mapes], label='Train MAPE')\n",
    "plt.plot([m*100 for m in val_mapes], label='Val MAPE')\n",
    "plt.title('MAPE Curve'); plt.xlabel('Epoch'); plt.ylabel('MAPE (%)'); plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdb27c",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50fd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
