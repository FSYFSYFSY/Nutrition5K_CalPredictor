{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08eaaeca",
   "metadata": {},
   "source": [
    "## Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8fc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe764f1b",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e48cf",
   "metadata": {},
   "source": [
    "### Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2111b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 if_train = True,\n",
    "                 data_dir = \"train\",\n",
    "                 color_dir = \"color\",\n",
    "                 depth_dir = \"depth_raw\",\n",
    "                 rgb_name = \"rgb.png\",\n",
    "                 depth_name=\"depth_raw.png\",\n",
    "                 csv_name = \"nutrition5k_train.csv\",\n",
    "                 transform = False,\n",
    "                 ):\n",
    "        self.root = root\n",
    "        self.data = self.root / data_dir\n",
    "        self.color_dir  = self.data / color_dir\n",
    "        self.depth_dir = self.data / depth_dir\n",
    "        self.rgb_name = rgb_name\n",
    "        self.depth_name = depth_name\n",
    "        self.if_train = if_train\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.if_train:\n",
    "            df = pd.read_csv(self.root / csv_name)\n",
    "            self.id2cal = {str(r[\"ID\"]) : float(r[\"Value\"]) for _, r in df.iterrows()}\n",
    "\n",
    "        rgb_paths = sorted((p / rgb_name for p in self.color_dir.glob(\"dish_*\") if (p / rgb_name).exists()))\n",
    "        if not rgb_paths:\n",
    "            raise RuntimeError(f\"Found 0 images in {self.color_dir}.\")\n",
    "        \n",
    "        self.samples = []\n",
    "        if self.if_train:\n",
    "            for rgb_path in rgb_paths:\n",
    "                dish_id = rgb_path.parent.name\n",
    "                if dish_id not in self.id2cal:\n",
    "                    print(f\"Warning: {dish_id} not found in CSV.\")\n",
    "                depth_path = None\n",
    "                if self.depth_dir is not None:\n",
    "                    depth_path = self.depth_dir / dish_id / self.depth_name\n",
    "\n",
    "                self.samples.append((rgb_path, depth_path, self.id2cal[dish_id]))\n",
    "\n",
    "        else:\n",
    "            for rgb_path in rgb_paths:\n",
    "                dish_id = rgb_path.parent.name\n",
    "                depth_path = None\n",
    "                if self.depth_dir is not None:\n",
    "                    depth_path = self.depth_dir / dish_id / self.depth_name\n",
    "\n",
    "                self.samples.append((rgb_path, depth_path, None))\n",
    "                \n",
    "        #print(f\"Total samples: {len(self.samples)}\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path, depth_path, cal = self.samples[idx]\n",
    "        rgb = Image.open(rgb_path).convert(\"RGB\")\n",
    "        depth = Image.open(depth_path).convert(\"L\")\n",
    "\n",
    "        rgb = self.to_tensor(rgb) \n",
    "        depth = self.to_tensor(depth)\n",
    "\n",
    "        if self.if_train == True:\n",
    "            cal = torch.tensor(cal, dtype=torch.float32)\n",
    "            return rgb, depth, cal\n",
    "        else:\n",
    "            return rgb, depth\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb7bd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/lhg45/Desktop/COMP90086/PJ/Nutrition5K\n"
     ]
    }
   ],
   "source": [
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73698119",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MyDataset(root=Path.cwd(), if_train=True, transform=False)\n",
    "test_set = MyDataset(root=Path.cwd(), data_dir=\"test\", if_train=False, transform=False)\n",
    "\n",
    "dataset_size = len(train_set)\n",
    "val_ratio = 0.1\n",
    "val_size = int(dataset_size * val_ratio)\n",
    "train_size = dataset_size - val_size\n",
    "train_subset, val_subset = random_split(train_set, [train_size, val_size])\n",
    "\n",
    "#torch.manual_seed(42) \n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=32, shuffle=False,\n",
    "                          num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a959b7",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3080a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(c_in, c_out, k=5, s=1, p=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(c_in, c_out, kernel_size=k, stride=s, padding=p, bias=False),\n",
    "        nn.BatchNorm2d(c_out),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class RGBBranch(nn.Module):\n",
    "    def __init__(self, in_ch=3):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            conv_block(in_ch, 32),                \n",
    "            conv_block(32, 32),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(32, 64),\n",
    "            conv_block(64, 64),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(64, 128),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(128, 256),\n",
    "            nn.MaxPool2d(2),                     \n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.gap(x).flatten(1)               \n",
    "        return x\n",
    "\n",
    "class DepthBranch(nn.Module):\n",
    "    def __init__(self, in_ch=1):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            conv_block(in_ch, 16),\n",
    "            conv_block(16, 16),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(16, 32),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(32, 64),\n",
    "            nn.MaxPool2d(2),                      \n",
    "            conv_block(64, 128),\n",
    "            nn.MaxPool2d(2),                      \n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.gap(x).flatten(1)              \n",
    "        return x\n",
    "\n",
    "class RGBDNet(nn.Module):\n",
    "\n",
    "    def __init__(self, use_dropout=True):\n",
    "        super().__init__()\n",
    "        self.rgb = RGBBranch(3)\n",
    "        self.depth = DepthBranch(1)\n",
    "\n",
    "        fusion_dim = 256 + 128\n",
    "        mlp = [\n",
    "            nn.Linear(fusion_dim, 128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        if use_dropout:\n",
    "            mlp.append(nn.Dropout(0.1))\n",
    "        mlp += [\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1)\n",
    "        ]\n",
    "        self.head = nn.Sequential(*mlp)\n",
    "\n",
    "    def forward(self, rgb, depth):\n",
    "        f_rgb = self.rgb(rgb)       \n",
    "        f_d   = self.depth(depth)    \n",
    "        f     = torch.cat([f_rgb, f_d], dim=1)\n",
    "        out   = self.head(f).squeeze(1)  \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b764af9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0c14a94",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/lhg45/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/lhg45/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/home/lhg45/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/dataset.py\", line 416, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_8828/1119226410.py\", line 62, in __getitem__\n    rgb = self.to_tensor(rgb)\n          ^^^^^^^^^^^^^^\nAttributeError: 'MyDataset' object has no attribute 'to_tensor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m model.train()\n\u001b[32m     14\u001b[39m running_loss, mape_sum, n_batches = \u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1516\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1514\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1515\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1551\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/_utils.py:769\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mAttributeError\u001b[39m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/lhg45/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/lhg45/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/home/lhg45/conda/envs/Pytorch2/lib/python3.13/site-packages/torch/utils/data/dataset.py\", line 416, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_8828/1119226410.py\", line 62, in __getitem__\n    rgb = self.to_tensor(rgb)\n          ^^^^^^^^^^^^^^\nAttributeError: 'MyDataset' object has no attribute 'to_tensor'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RGBDNet()  \n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_mapes, val_mapes = [], []\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, mape_sum, n_batches = 0.0, 0.0, 0\n",
    "\n",
    "    for rgb, depth, cal, _ids in train_loader:\n",
    "        rgb, depth, cal = rgb.to(device), depth.to(device), cal.to(device)\n",
    "        pred = model(rgb, depth).squeeze(1) \n",
    "        loss = criterion(pred, cal)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * rgb.size(0)\n",
    "        mape_batch = torch.mean(torch.abs((pred - cal) / (cal + 1e-8))).item()\n",
    "        mape_sum += mape_batch\n",
    "        n_batches += 1\n",
    "\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_mape = mape_sum / n_batches\n",
    "    train_losses.append(train_loss)\n",
    "    train_mapes.append(train_mape)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, mape_sum, n_batches = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for rgb, depth, cal, _ids in val_loader:\n",
    "            rgb, depth, cal = rgb.to(device), depth.to(device), cal.to(device)\n",
    "            pred = model(rgb, depth).squeeze(1)\n",
    "            loss = criterion(pred, cal)\n",
    "            val_loss += loss.item() * rgb.size(0)\n",
    "            mape_batch = torch.mean(torch.abs((pred - cal) / (cal + 1e-8))).item()\n",
    "            mape_sum += mape_batch\n",
    "            n_batches += 1\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_mape = mape_sum / n_batches\n",
    "    val_losses.append(val_loss)\n",
    "    val_mapes.append(val_mape)\n",
    "\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Train MAPE: {train_mape*100:.3f}%, Val MAPE: {val_mape*100:.3f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40963b3",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f9e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('MSE Loss Curve'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot([m*100 for m in train_mapes], label='Train MAPE')\n",
    "plt.plot([m*100 for m in val_mapes], label='Val MAPE')\n",
    "plt.title('MAPE Curve'); plt.xlabel('Epoch'); plt.ylabel('MAPE (%)'); plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bdb27c",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50fd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pytorch2)",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
